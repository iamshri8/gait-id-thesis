{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Metrics Learning Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scripts.data import prepare_pose, read_data, split_data_metrics_learning, get_req_ids, train_test, subsample\n",
    "from scripts.model_config import base_model, offline_triplet_network, online_triplet_network\n",
    "from scripts.losses import offline_triplet_loss\n",
    "from tensorflow_addons.losses.triplet import triplet_semihard_loss\n",
    "from scripts.offline_triplet_generator import offline_triplet_generator\n",
    "from scripts.train import train\n",
    "from scripts.evaluate import generate_embedding, build_annoy_index\n",
    "from scripts.metrics import get_metrics\n",
    "from scripts.model_eval_on_epoch_end import EvalOnEpochEnd\n",
    "from scripts.mlflow_logger import MLFlowLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1 for seat ids 2|3 and 0 for seat ids 0|1 ::\n",
      "Camera perpective shape for each sequence::  (978,)\n",
      "-----------------------------------------------------------------\n",
      "Remove camera perpective dim from (978, 2, 120, 75)\n",
      "Actual Pose shape after removing perspective dim::  (978, 120, 75)\n",
      "-----------------------------------------------------------------\n",
      "Reshape the last dim (pose - 75) into (x,y,score - 25 x 3)\n",
      "Actual Pose shape ::  (978, 120, 25, 3)\n",
      "-----------------------------------------------------------------\n",
      "Eliminate score from (x,y,score) - 25 x 3 to get pose coordinates or 25-Joints(x,y) - 25 x 2\n",
      "Actual Pose shape ::  (978, 120, 25, 2)\n",
      "-----------------------------------------------------------------\n",
      "Consider only 11 Joints - (7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 23) out of 25 joints\n",
      "Pick only the required joints from the actual pose which has all the 25 joints.\n",
      "-----------------------------------------------------------------\n",
      "Reshape the joints from 2d (11 x 2) to 1d (22,)\n",
      "FINAL Actual Pose shape ::  (978, 120, 22)\n"
     ]
    }
   ],
   "source": [
    "# Read data.h5 and preprocess the poses.\n",
    "extracted_poses, transformed_poses, target = read_data(path=\"./data/data_v2.h5\")\n",
    "person_ids = target[:,0]\n",
    "seat_ids = target[:,1]\n",
    "actual_pose = prepare_pose(transformed_poses, seat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations.\n",
    "cfg = {\n",
    "    #data config\n",
    "    'actual_pose': actual_pose,\n",
    "    'target': target,\n",
    "    'person_ids': person_ids,\n",
    "    'val_ids': [1, 3, 4, 19, 20], # The ids mentioned will be the validation ids and the rest is taken for training.\n",
    "    'num_of_val_ids': 5, # No. of val ishape per experiment. This is equivalent to the number of users using the car.\n",
    "    'window_width' : 90,\n",
    "    'overlap': 0.5,\n",
    "    'random_state': 32, # For picking random sequences for anchor and gallery set.\n",
    "    'random_seed': 45, # For picking random validation ids for the experiment.\n",
    "    'augment_data': True, # or False -- Setting this False will avoid data augmentation.\n",
    "    'anchor_gallery_split_size': 0.2, # % of anchor gallery split. Ex. 0.2 => 20% for anchor set and the rest for gallery set.\n",
    "    'num_of_joints': 11,\n",
    "        \n",
    "    #triplet mining\n",
    "    'mining': 'offline', # or 'online' -- Setting which mining strategy should be used. It could be online or offline.\n",
    "    \n",
    "    #model config\n",
    "    'lstm_dropout': 0.8, # Dropout in LSTM units for offline model.\n",
    "    '1d_spatial_dropout': 0.2, # Dropout in 1D Convolution block for offline model.\n",
    "    'normal_dropout': 0.8, # Dropout for online mining model. \n",
    "    'vec_dim': 128, # No. of dimensions of the feature vector that represents the gait sequence.\n",
    "    'epochs': 2,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001, # Learning rate of Adam optimizer.\n",
    "    'ckpt_dir' : './models/', # Directory to which the model is saved after each epoch.\n",
    "    'eval_interval': 3, # Interval in which the model is evaluated while training. Ex. setting this to 1 => evaluate model performance once for every 3 epochs.\n",
    "    \n",
    "    #experiment config\n",
    "    'n_times_train': 10, # If this value is set to 10, then 10 different set of validation ids are selected and therefore 10 different experiments will run.\n",
    "    \n",
    "    #model path for inference.\n",
    "    'model_path_inference': './models/model-val-[9, 14, 16, 20, 3]-90-128-offline.h5'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aev32/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2260\t Train Metrics - epoch: 1 - rank1_acc: 0.380000 - mAP: 0.489092\n",
      "\t Val Metrics - epoch: 1 - rank1_acc: 0.540000 - mAP: 0.538710\n",
      "22/22 [==============================] - 20s 888ms/step - loss: 0.2260 - val_loss: 0.1886\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2106\t Train Metrics - epoch: 2 - rank1_acc: 0.380000 - mAP: 0.481740\n",
      "\t Val Metrics - epoch: 2 - rank1_acc: 0.500000 - mAP: 0.509027\n",
      "22/22 [==============================] - 18s 821ms/step - loss: 0.2106 - val_loss: 0.1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aev32/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2235\t Train Metrics - epoch: 1 - rank1_acc: 0.420000 - mAP: 0.552817\n",
      "\t Val Metrics - epoch: 1 - rank1_acc: 0.375000 - mAP: 0.463690\n",
      "23/23 [==============================] - 21s 900ms/step - loss: 0.2235 - val_loss: 0.2105\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2099\t Train Metrics - epoch: 2 - rank1_acc: 0.500000 - mAP: 0.571961\n",
      "\t Val Metrics - epoch: 2 - rank1_acc: 0.458333 - mAP: 0.526324\n",
      "23/23 [==============================] - 19s 806ms/step - loss: 0.2099 - val_loss: 0.2064\n"
     ]
    }
   ],
   "source": [
    "random.seed(cfg['random_seed'])\n",
    "for _ in range(cfg['n_times_train']):\n",
    "    val_ids = random.sample(range(1, 21), cfg['num_of_val_ids'])\n",
    "    cfg['val_ids'] = val_ids\n",
    "    train(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aev32/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "/home/aev32/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:820: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if (isinstance(inputs, collections.Sequence)\n",
      "/home/aev32/anaconda3/envs/keras_env/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"query_input:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"positive_input:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"negative_input:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"input_2:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"input_2:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 90, 22) for input Tensor(\"input_2:0\", shape=(None, 90, 22), dtype=float32), but it was called on an input with incompatible shape (None, 120, 22).\n",
      "Avg acc is :: 0.28\n",
      "Rank 10 acc is :: 1.0\n",
      "Rank 5 acc is :: 0.92\n",
      "Rank 1 acc is :: 0.46\n",
      "Mean Avg Precision is :: 0.5496943121693121\n",
      "Vote res ::  0.46\n",
      "Rank1 Accuracy  0.46 mean Average Precision  0.5496943121693121\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = keras.models.load_model(cfg['model_path_inference'], custom_objects={'offline_triplet_loss': offline_triplet_loss, 'tf':tf})\n",
    "\n",
    "# Obtain anchor and gallery set.\n",
    "X_set, y_set = get_req_ids(cfg['actual_pose'], cfg['target'], cfg['val_ids'], cfg['person_ids'])\n",
    "X_gal, X_anchor, y_gal, y_anchor = train_test(X_set, y_set, test_size=cfg['anchor_gallery_split_size'], random_state=cfg['random_state'], stratify=y_set)\n",
    "X_gal, y_gal = subsample(cfg=cfg, poses=X_gal, targets=y_gal, window_width = cfg['window_width'], overlap = cfg['overlap'])\n",
    "\n",
    "# Generate feature vectors for the gallery set and generate the embedding space.\n",
    "embedding_dict = generate_embedding(cfg, model, X_gal)\n",
    "\n",
    "# Use Annoy library for indexing the feature vector so that k-Nearest neighbor can be retrived.\n",
    "annoy_index = build_annoy_index(cfg, embedding_dict=embedding_dict)\n",
    "\n",
    "# Print all evaluation metrics, rank-1, rank-5, rank-10 accuracy, mean Average Precision, most voted rank-10 accuracy and average correct resutls(accuracy).\n",
    "rank1_acc , mAP = get_metrics(cfg, model, X_anchor, y_anchor, X_gal, y_gal, annoy_index, cfg['vec_dim'])\n",
    "\n",
    "print('Rank1 Accuracy ', rank1_acc, 'mean Average Precision ', mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
