{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard Visualization of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from tensorboard.plugins import projector\n",
    "from scripts.losses import offline_triplet_loss\n",
    "from tensorflow_addons.losses.triplet import triplet_semihard_loss\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from scripts.data import prepare_pose, read_data, augment_data, split_data_metrics_learning, get_req_ids, train_test, subsample\n",
    "from scripts.evaluate import generate_embedding, build_annoy_index\n",
    "from scripts.metrics import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data.h5 and preprocess the poses.\n",
    "extracted_poses, transformed_poses, target = read_data(path=\"./data/data_v2.h5\")\n",
    "person_ids = target[:,0]\n",
    "seat_ids = target[:,1]\n",
    "actual_pose = prepare_pose(transformed_poses, seat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations.\n",
    "cfg = {\n",
    "    #data config\n",
    "    'actual_pose': actual_pose,\n",
    "    'target': target,\n",
    "    'person_ids': person_ids,\n",
    "    'val_ids': [1, 3],\n",
    "    'num_of_val_ids': 5,\n",
    "    'window_width' : 90,\n",
    "    'overlap': 0.5,\n",
    "    'random_state': 32,\n",
    "    'augment_data': True, # or False\n",
    "    'anchor_gallery_split_size': 0.2,\n",
    "    'num_of_joints': 11,\n",
    "        \n",
    "    #triplet mining\n",
    "    'mining': 'offline', # or 'online' \n",
    "    \n",
    "    #model config\n",
    "    'vec_dim': 128,\n",
    "    'model_path' : './models/model-val-[1, 3, 4, 19, 20]-90-128-offline.h5',\n",
    "    \n",
    "    #tensorboard\n",
    "    'logdir': \"tensorboard_logdir/visual_dir1/\",\n",
    "    'viz_mode': 'both' # or anchor or both\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains splits anchor and gallery set.\n",
    "\n",
    "X_set, y_set = get_req_ids(cfg['actual_pose'], cfg['target'], cfg['val_ids'], cfg['person_ids'])\n",
    "X_gal, X_anchor, y_gal, y_anchor = train_test(X_set, y_set, test_size=cfg['anchor_gallery_split_size'], random_state=cfg['random_state'], stratify=y_set)\n",
    "\n",
    "X_gal, y_gal = subsample(cfg=cfg, poses=X_gal, targets=y_gal, window_width = cfg['window_width'], overlap = cfg['overlap'])\n",
    "X_anchor, y_anchor = subsample(cfg=cfg, poses=X_gal, targets=y_gal, window_width = cfg['window_width'], overlap = cfg['overlap'])\n",
    "\n",
    "y_anchor += 100\n",
    "\n",
    "X_set = np.concatenate((X_gal, X_anchor))\n",
    "y_set = np.concatenate((y_gal, y_anchor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # log directory for storing tensorboard generated files.\n",
    "LOG_DIR = os.path.join(os.getcwd(), cfg['logdir'])\n",
    "\n",
    "# Load model from the model_path in the cfg.\n",
    "model = None\n",
    "model = keras.models.load_model(cfg['model_path'], custom_objects={'offline_triplet_loss': offline_triplet_loss, 'tf':tf})\n",
    "\n",
    "# Select the data for visualization. \n",
    "# Ex. gallery => visualize the feature vectors of the gallery set.\n",
    "# Ex. anchor  => visualize the feature vectors of the anchor set.\n",
    "# Ex. both => visualize the feature vectors of both the gallery set and the anchor set together.\n",
    "\n",
    "if cfg['viz_mode'] == 'gallery':\n",
    "    data = X_gal\n",
    "    label = y_gal\n",
    "elif cfg['viz_mode'] == 'anchor':\n",
    "    data = X_anchor\n",
    "    label = y_anchor\n",
    "elif cfg['viz_mode'] == 'both':\n",
    "    data = X_set\n",
    "    label = y_set\n",
    "    \n",
    "# Get all the feature vectors and put it in a dictionary.\n",
    "embedding_dict = generate_embedding(cfg, model, data)\n",
    "\n",
    "# Read all the feature vectors from the dictionary and store it in a numpy array.\n",
    "embeddings_array = np.zeros((len(embedding_dict), 128))\n",
    "for i, embed in enumerate(embedding_dict.values()):\n",
    "    embeddings_array[i] = embed\n",
    "    \n",
    "print(\"Embedding array : \", embeddings_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load the features in a tensorflow variable \n",
    "features = tf.Variable(embeddings_array, name='features')\n",
    "\n",
    "# Create checkpoint files for the model.\n",
    "checkpoint = tf.train.Checkpoint(embedding=model)\n",
    "checkpoint.save(os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "\n",
    "# Create a csv file for the label.\n",
    "np.savetxt(fname=os.path.join(LOG_DIR, \"metadata.csv\"), X=label, fmt='%0.0f')\n",
    "\n",
    "# Create a tf session.\n",
    "sess = tf.compat.v1.Session()\n",
    "saver = tf.compat.v1.train.Saver([features])\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'model.ckpt'))\n",
    "\n",
    "# Create a embedding projector config and write all the metadata on to it.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = features.name\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, \"metadata.csv\")\n",
    "\n",
    "# Saves a config file that TensorBoard will read during startup.\n",
    "projector.visualize_embeddings(LOG_DIR, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
